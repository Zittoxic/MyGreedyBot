{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import configparser\n",
    "from datetime import datetime\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gym\n",
    "import yfinance as yf\n",
    "from apscheduler.schedulers.blocking import BlockingScheduler\n",
    "from oandapyV20 import API\n",
    "import oandapyV20.endpoints.orders as orders\n",
    "from oandapyV20.contrib.requests import MarketOrderRequest\n",
    "from oanda_candles import Pair, Gran, CandleClient\n",
    "from oandapyV20.contrib.requests import TakeProfitDetails, StopLossDetails\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# Should try to ask the input date and mention the restriction or constrainst as the date limits for \n",
    "#each periods chosen\n",
    "# or try a for loop to find each period tmespan limits\n",
    "\n",
    "# Get today's date\n",
    "today = datetime.date.today()\n",
    "# Get today's date and time\n",
    "end = datetime.datetime.today()\n",
    "\n",
    "dax= yf.Ticker(\"^GDAXI\")\n",
    "\n",
    "############## Setup With input of the user #################################\n",
    "\n",
    "# Ask the user for input days and timeframe\n",
    "#input_time = int(input(\"Enter the chosen timeframe): \"))\n",
    "#max_start_date = today - datetime.timedelta(days=input_days)\n",
    "# Calculate the start date by subtracting the input number of days from today's date\n",
    "#try: \n",
    "#input_days = int(input(\"Enter the number of days of historical data to retrieve (cancel to get the default timespan for chosen timeframe): \"))\n",
    "#except()\n",
    "#dataF = yf.download(\"^GDAXI\", max_start_date, today, interval='5m')\n",
    "\n",
    "############## Default Setup  #################################\n",
    "\n",
    "max_start_date = today - datetime.timedelta(days=59)\n",
    "dataF = yf.download(\"^GDAXI\", max_start_date, today, interval='5m')\n",
    "\n",
    "\n",
    "\n",
    "#dataF = yf.download(\"^GDAXI\", start=\"2021-08-16\", end=\"2023-04-13\", interval='1h')\n",
    "#dataF.iloc[:,:]\n",
    "\n",
    "\n",
    "# Calculate the maximum start date by subtracting 60 days from today's date\n",
    "# it should have an input from the user for timestamp (x days of data) and the timeframe (data breaked in 5 min to days)\n",
    "#max_start_date = today - datetime.timedelta(days=60)\n",
    "#dax\n",
    "#dax_historical = dax.history(start=\"2023-02-16\", end=\"2023-04-13\", interval=\"5m\")\n",
    "#dax_historical\n",
    "\n",
    "\n",
    "\n",
    "# Get today's date\n",
    "#today = datetime.date.today()\n",
    "\n",
    "# Convert the date to string in the desired format\n",
    "#today_str = today.strftime('%Y-%m-%d')\n",
    "#print(today_str)\n",
    "\n",
    "# Calculate the start date by subtracting 60 days from today's date\n",
    "#start_date = today - datetime.timedelta(days=60)\n",
    "\n",
    "# Convert the start date to string in the desired format\n",
    "#start_date_str = start_date.strftime('%Y-%m-%d')\n",
    "#print(start_date_str)\n",
    "\n",
    "# Get historical data for DAX index\n",
    "#dax = yf.Ticker(\"^GDAXI\")\n",
    "#dax_historical = dax.history(start=start_date_str, end=today_str, interval=\"5m\")\n",
    "\n",
    "# Print the historical data\n",
    "#print(dax_historical)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start day:  2023-03-03 , end date:  2023-05-02\n",
      "{'maxAge': 86400, 'priceHint': 2, 'previousClose': 15922.38, 'open': 15950.36, 'dayLow': 15842.79, 'dayHigh': 16011.56, 'regularMarketPreviousClose': 15922.38, 'regularMarketOpen': 15950.36, 'regularMarketDayLow': 15842.79, 'regularMarketDayHigh': 16011.56, 'volume': 0, 'regularMarketVolume': 0, 'averageVolume': 79678581, 'averageVolume10days': 69341390, 'averageDailyVolume10Day': 69341390, 'bid': 0.0, 'ask': 0.0, 'bidSize': 0, 'askSize': 0, 'fiftyTwoWeekLow': 11862.84, 'fiftyTwoWeekHigh': 16011.56, 'fiftyDayAverage': 15469.258, 'twoHundredDayAverage': 14191.737, 'currency': 'EUR', 'exchange': 'GER', 'quoteType': 'INDEX', 'symbol': '^GDAXI', 'underlyingSymbol': '^GDAXI', 'shortName': 'DAX PERFORMANCE-INDEX', 'longName': 'DAX PERFORMANCE-INDEX', 'firstTradeDateEpochUtc': 567849600, 'timeZoneFullName': 'Europe/Berlin', 'timeZoneShortName': 'CEST', 'uuid': '65bce022-dcbb-3a6c-bf5a-bce616eefe76', 'messageBoardId': 'finmb_INDEXGDAXI', 'gmtOffSetMilliseconds': 7200000, 'trailingPegRatio': None}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'max_date_str' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 68\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[39mprint\u001b[39m(dax_info)\n\u001b[0;32m     67\u001b[0m \u001b[39m#max_date_str = dax_info['regularMarketPreviousCloseDate']\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m max_date \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mstrptime(max_date_str, \u001b[39m'\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm-\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mdate()\n\u001b[0;32m     70\u001b[0m \u001b[39mif\u001b[39;00m start_date \u001b[39m<\u001b[39m max_start_date:\n\u001b[0;32m     71\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe requested data is older than \u001b[39m\u001b[39m{\u001b[39;00mmax_start_date_str\u001b[39m}\u001b[39;00m\u001b[39m, retrieving the maximum amount of available data.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'max_date_str' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get today's date\n",
    "today = datetime.date.today()\n",
    "\n",
    "# Calculate the maximum start date by subtracting 60 days from today's date\n",
    "# it should have an input from the user for timestamp (x days of data) and the timeframe (data breaked in 5 min to days)\n",
    "max_start_date = today - datetime.timedelta(days=60)\n",
    "\n",
    "# Convert the dates to string in the desired format\n",
    "today_str = today.strftime('%Y-%m-%d')\n",
    "max_start_date_str = max_start_date.strftime('%Y-%m-%d')\n",
    "print('Start day: ', max_start_date_str, ', end date: ', today_str)\n",
    "\n",
    "\n",
    "\n",
    "# Ask the user for input days\n",
    "#try: \n",
    "input_days = int(input(\"Enter the number of days of historical data to retrieve (cancel to get the default timespan for chosen timeframe): \"))\n",
    "#except()\n",
    "\n",
    "# Calculate the start date by subtracting the input number of days from today's date\n",
    "start_date = today - datetime.timedelta(days=input_days)\n",
    "\n",
    "# Convert the start date to string in the desired format\n",
    "start_date_str = start_date.strftime('%Y-%m-%d')\n",
    "\n",
    "# Check if the requested data is available\n",
    "dax = yf.Ticker(\"^GDAXI\")\n",
    "dax_info = dax.info\n",
    "print(dax_info)\n",
    "#max_date_str = dax_info['regularMarketPreviousCloseDate']\n",
    "max_date = datetime.datetime.strptime(max_date_str, '%Y-%m-%d').date()\n",
    "\n",
    "if start_date < max_start_date:\n",
    "    print(f\"The requested data is older than {max_start_date_str}, retrieving the maximum amount of available data.\")\n",
    "    start_date = max_start_date\n",
    "    start_date_str = max_start_date_str\n",
    "    input_days = (today - start_date).days\n",
    "\n",
    "if start_date < max_date:\n",
    "    try:\n",
    "        # Get historical data for DAX index\n",
    "        dax_historical = dax.history(start=start_date_str, end=today_str, interval=\"5m\")\n",
    "\n",
    "        # Print the historical data\n",
    "        print(dax_historical)\n",
    "    except ValueError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(f\"The requested data is not available for the specified range.\")\n",
    "        response = input(f\"Do you want to retrieve the available data from {start_date_str} to {max_date_str}? (y/n): \")\n",
    "        if response.lower() == 'y':\n",
    "            dax_historical = dax.history(start=start_date_str, end=max_date_str, interval=\"5m\")\n",
    "            print(dax_historical)\n",
    "        else:\n",
    "            print(\"Exiting program...\")\n",
    "            exit()\n",
    "else:\n",
    "    print(f\"The requested data is not available. The maximum available data is from {max_date_str} ({(today - max_date).days} days).\")\n",
    "    response = input(\"Do you want to continue? (y/n): \")\n",
    "    if response.lower() == 'y':\n",
    "        start_date = max_date\n",
    "        start_date_str = max_date_str\n",
    "        input_days = (today - start_date).days\n",
    "        dax_historical = dax.history(start=start_date_str, end=today_str, interval=\"5m\")\n",
    "        print(dax_historical)\n",
    "    else:\n",
    "        print(\"Exiting program...\")\n",
    "        exit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dax_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 12\u001b[0m\n\u001b[0;32m      6\u001b[0m end_date \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mTimestamp\u001b[39m.\u001b[39mtoday()\u001b[39m.\u001b[39mstrftime(\u001b[39m\"\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm-\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[39m# Get the historical data for the DAX30\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39m#dax_data = yf.download(ticker, start=start_date, end=end_date)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \n\u001b[0;32m     11\u001b[0m \u001b[39m# Save the data to a CSV file\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m dax_data\u001b[39m.\u001b[39mto_csv(\u001b[39m'\u001b[39m\u001b[39mdax30.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[39m# Get the historical data for the DAX30 including volume data\u001b[39;00m\n\u001b[0;32m     14\u001b[0m dax_data \u001b[39m=\u001b[39m yf\u001b[39m.\u001b[39mdownload(ticker, start\u001b[39m=\u001b[39mstart_date, end\u001b[39m=\u001b[39mend_date, interval\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m5m\u001b[39m\u001b[39m\"\u001b[39m,group_by\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mticker\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dax_data' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set the ticker symbol for DAX30\n",
    "ticker = \"^GDAXI\"\n",
    "\n",
    "# Set the start and end dates for the data you want to retrieve\n",
    "start_date = \"2023-02-16\"\n",
    "end_date = pd.Timestamp.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Get the historical data for the DAX30\n",
    "#dax_data = yf.download(ticker, start=start_date, end=end_date)\n",
    "\n",
    "# Save the data to a CSV file\n",
    "dax_data.to_csv('dax30.csv')\n",
    "# Get the historical data for the DAX30 including volume data\n",
    "dax_data = yf.download(ticker, start=start_date, end=end_date, interval=\"5m\",group_by='ticker')\n",
    "dax_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result is: 2500.0\n"
     ]
    }
   ],
   "source": [
    "# Set the initial capital constant\n",
    "INIT_CAPITAL = 5000\n",
    "\n",
    "# Set the configuration file path\n",
    "CONFIG_FILE = 'config.ini'\n",
    "\n",
    "# Check if the configuration file exists \n",
    "if not os.path.exists(CONFIG_FILE):\n",
    "    # Create a new configuration file with a default value for INIT_CAPITAL\n",
    "    config = configparser.ConfigParser()\n",
    "    config['MY_SECTION'] = {'DATE': str(datetime.now().date()),\n",
    "                            'INIT_CAPITAL': str(INIT_CAPITAL),\n",
    "                            'BALANCE': str(INIT_CAPITAL)}\n",
    "    with open(CONFIG_FILE, 'w') as configfile:\n",
    "        config.write(configfile)\n",
    "        \n",
    "#Read the current date and balance from the configuration file\n",
    "config = configparser.ConfigParser()\n",
    "config.read(CONFIG_FILE)\n",
    "current_date = datetime.strptime(config['MY_SECTION']['DATE'], '%Y-%m-%d').date()\n",
    "current_balance = float(config['MY_SECTION']['BALANCE'])\n",
    "\n",
    "# Calculate the new balance by adding the daily amount to the current balance\n",
    "daily_amount = 100 # Replace this with your daily amount\n",
    "new_balance = current_balance + daily_amount\n",
    "\n",
    "# Update the configuration file with the new date and balance\n",
    "config['MY_SECTION']['DATE'] = str(datetime.now().date())\n",
    "config['MY_SECTION']['BALANCE'] = str(new_balance)\n",
    "with open(CONFIG_FILE, 'w') as configfile:\n",
    "    config.write(configfile)\n",
    "\n",
    "monthlyInterestGains = 50\n",
    "result = INIT_CAPITAL * monthlyInterestGains / 100\n",
    "print(f\"The result is: {result}\")\n",
    "\n",
    "\n",
    "###########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disered Daily Gains percentage: 2.27%\n"
     ]
    }
   ],
   "source": [
    "totalWorkingDayOfThisMonth=22\n",
    "dailyInterestGains = monthlyInterestGains/totalWorkingDayOfThisMonth\n",
    "print(f\"Disered Daily Gains percentage: {dailyInterestGains:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbolTickValue = 2.5\n",
    "symbolName = Dax\n",
    "symbolAbreviation = Dax\n",
    "lot= 1\n",
    "miniLot = .1\n",
    "microlot = .01\n",
    "lotIsvested = microlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Margin required: €196.125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n//C++ code\\n#include <iostream>\\nusing namespace std;\\n\\nint main() {\\n    float contract_size = 25; // €25 per index point\\n    float market_price = 15000; // current market price in points\\n    int leverage = 10; // 1:10 leverage\\n\\n    float total_trade_value = contract_size * market_price;\\n    float margin_required = total_trade_value / leverage;\\n\\n    cout << \"Margin required: €\" << margin_required << endl;\\n    return 0;\\n}\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#need to calculate margin\n",
    "contract_size = 2.5 # €25 per index points\n",
    "market_price = 15690 # current market price in points\n",
    "leverage = 200 # 1:20 leverage\n",
    "\n",
    "total_trade_value = contract_size * market_price\n",
    "margin_required = total_trade_value / leverage\n",
    "\n",
    "print(f\"Margin required: €{margin_required}\")\n",
    "\n",
    "\"\"\"\n",
    "//C++ code\n",
    "#include <iostream>\n",
    "using namespace std;\n",
    "\n",
    "int main() {\n",
    "    float contract_size = 25; // €25 per index point\n",
    "    float market_price = 15000; // current market price in points\n",
    "    int leverage = 10; // 1:10 leverage\n",
    "\n",
    "    float total_trade_value = contract_size * market_price;\n",
    "    float margin_required = total_trade_value / leverage;\n",
    "\n",
    "    cout << \"Margin required: €\" << margin_required << endl;\n",
    "    return 0;\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Margin required: €196.125\n",
      "Available Margin: €4411.625\n",
      "ROI in 22 days: €2729.90\n",
      "ROI in 1 day: €113.64\n",
      "Pips to do in 1 day: 11363.64\n",
      "lotIsvestedX in 1 day: 0.11\n",
      "lots value: €0.28\n",
      "Compound 1 month: €6250.00\n",
      "Disered Daily Gains percentage: 2.27%\n",
      "ROI in 1 week: €568.18\n",
      "ROI in 1 month: €2272.73\n"
     ]
    }
   ],
   "source": [
    "print(f\"Margin required: €{margin_required}\")\n",
    "if (margin_required*3 < INIT_CAPITAL):\n",
    "    print(f\"Available Margin: €{INIT_CAPITAL - margin_required*3}\")\n",
    "\n",
    "#calculate pips necessary to make the Maximal outcome a day a day\n",
    "x = (INIT_CAPITAL*(1.02)**22)-INIT_CAPITAL\n",
    "\n",
    "print(f\"ROI in 22 days: €{x:.2f}\")\n",
    "\n",
    "xx = dailyInterestGains/100 * INIT_CAPITAL\n",
    "pips_in_a_day=xx/lotIsvested\n",
    "lotIsvestedX=xx/1000\n",
    "x3=lotIsvestedX*2.5\n",
    "print(f\"ROI in 1 day: €{xx:.2f}\")\n",
    "print(f\"Pips to do in 1 day: {pips_in_a_day:.2f}\")\n",
    "print(f\"lotIsvestedX in 1 day: {lotIsvestedX:.2f}\")\n",
    "print(f\"lots value: €{x3:.2f}\")\n",
    "print(f\"Compound 1 month: €{x3*1000*22:.2f}\")\n",
    "print(f\"Disered Daily Gains percentage: {dailyInterestGains:.2f}%\")\n",
    "print(f\"ROI in 1 week: €{xx*5:.2f}\")\n",
    "print(f\"ROI in 1 month: €{xx*5*4:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.493945188017847"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2= INIT_CAPITAL/margin_required\n",
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trying to read a market past from various timeframes and find the best spikes and scan the internet\\nto find fundamental analisys cues that support the spikes\\nalso thecnical analysis that preceeds the spikes and check if they were recorrent throu the past iteretions\\nand make a statistical table and rules for the entry above certain % and staying in a trade'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"trying to read a market past from various timeframes and find the best spikes and scan the internet\n",
    "to find fundamental analisys cues that support the spikes\n",
    "also thecnical analysis that preceeds the spikes and check if they were recorrent throu the past iteretions\n",
    "and make a statistical table and rules for the entry above certain % and staying in a trade\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Want to randomize Coupon Collector's Problem formula"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import random\n",
    "# Set initial values for the number of scrolls and runs\n",
    "whiteScroll = 100\n",
    "whiteRuns = 0\n",
    "greenScroll = 600\n",
    "greenRuns = 0\n",
    "redScroll = 950\n",
    "redRuns = 0\n",
    "\n",
    "# Set the maximum and minimum number of scrolls dropped for each scroll type\n",
    "whiteMaxDrop = 36\n",
    "greenMaxDrop = 16\n",
    "redMaxDrop = 12\n",
    "whiteMinDrop = 24\n",
    "greenMinDrop = 11\n",
    "redMinDrop = 6\n",
    "\n",
    "# Initialize variables to keep track of the average number of scrolls dropped\n",
    "whiteAvarageDrop = 0\n",
    "greenAvarageDrop = 0\n",
    "redAvarageDrop = 0\n",
    "\n",
    "# Initialize variables to keep track of the number of scrolls collected for each type\n",
    "whiteScrollCollected = 0\n",
    "greenScrollCollected = 0\n",
    "redScrollCollected = 0\n",
    "\n",
    "# Initialize the number of runs to zero\n",
    "numRuns = 0\n",
    "\n",
    "# Keep running the loop until enough red scrolls have been collected\n",
    "while redScrollCollected < redScroll:\n",
    "\n",
    "# Increment the number of runs\n",
    "    numRuns += 1\n",
    "\n",
    "# If all green scrolls have been collected, start collecting red scrolls\n",
    "    if (greenScrollCollected == greenScroll):\n",
    "        if (redScrollCollected == 0):\n",
    "            # Set the number of runs to reach this point minus one, since this is the first run for red scrolls\n",
    "            greenRuns = numRuns - 1\n",
    "\n",
    "        # Generate a random number between the minimum and maximum number of red scrolls dropped\n",
    "        myRand = random.randint(redMinDrop, redMaxDrop)\n",
    "        print(\"myRand RED \", myRand, \".\")\n",
    "\n",
    "        # If the total number of scrolls dropped is less than or equal to the required number of red scrolls\n",
    "        if ((myRand + redScrollCollected) <= redScroll):\n",
    "            # Add the number of scrolls to the total number collected\n",
    "            redScrollCollected += myRand\n",
    "            print(\"All red scrolls collected so far OUT\", redScrollCollected, \".\")\n",
    "        # If the total number of scrolls dropped is greater than the required number of red scrolls\n",
    "        elif ((myRand + redScrollCollected + myRand) > redScroll):\n",
    "            # Add the remaining number of red scrolls to the total number collected\n",
    "            print(\"the diferense is\", redScroll - redScrollCollected, \".\")\n",
    "            redScrollCollected += redScroll - redScrollCollected\n",
    "        print(\"All red scrolls collected so far OUT\", redScrollCollected, \".\")\n",
    "\n",
    "    # If all white scrolls have been collected, start collecting green scrolls\n",
    "    if (whiteScrollCollected == whiteScroll):\n",
    "        if (greenScrollCollected == 0):\n",
    "            # Set the number of runs to reach this point minus one, since this is the first run for green scrolls\n",
    "            whiteRuns = numRuns - 1\n",
    "\n",
    "        # Generate a random number between the minimum and maximum number of green scrolls dropped\n",
    "        myRand = random.randint(greenMinDrop, greenMaxDrop)\n",
    "        print(\"myRand GREEN \", myRand, \".\")\n",
    "\n",
    "        # If the total number of scrolls dropped is less than or equal to the required number of green scrolls\n",
    "        if ((myRand + greenScrollCollected) <= greenScroll):\n",
    "            # Add the number of scrolls to the total number collected\n",
    "            greenScrollCollected += myRand\n",
    "            print(\"All green scrolls collected so far OUT\", greenScrollCollected, \".\")\n",
    "        # If the total number of scrolls dropped is greater than the required number of green scrolls\n",
    "        elif((myRand+greenScrollCollected+myRand)>greenScroll):\n",
    "            print(\"the diferense is\", greenScroll-greenScrollCollected, \".\")\n",
    "            greenScrollCollected += greenScroll-greenScrollCollected            \n",
    "        #greenRuns+=1\n",
    "        #greenAvarageDrop = greenScrollCollected/greenRuns\n",
    "        #print(\"All green AVARAGE scrolls collected in\", greenAvarageDrop, \".\")\n",
    "        \n",
    "    if (whiteScrollCollected<whiteScroll):\n",
    "        myRand = random.randint(whiteMinDrop, whiteMaxDrop)\n",
    "        print(\"This run droped WHITE\", myRand, \".\")\n",
    "        \n",
    "        if ((myRand+whiteScrollCollected)<=whiteScroll):\n",
    "            whiteScrollCollected += myRand\n",
    "            print(\"All white scrolls collected so far OUT\", whiteScrollCollected, \".\")\n",
    "        elif((myRand+whiteScrollCollected+myRand)>whiteScroll):\n",
    "            print(\"the diference is\", whiteScroll-whiteScrollCollected, \".\")\n",
    "            whiteScrollCollected += whiteScroll-whiteScrollCollected\n",
    "         #Calculate the avarage\n",
    "        whiteRuns+=1\n",
    "        whiteAvarageDrop = whiteScrollCollected/whiteRuns\n",
    "        print(\"All WHITE AVARAGE scrolls collected in\", whiteAvarageDrop, \".\")\n",
    "     \n",
    "\n",
    "print(\"All WHITE scrolls collected in\", whiteRuns, \"runs\")\n",
    "print(\"All GREEN scrolls collected in\", greenRuns, \"runs\")\n",
    "redRuns= numRuns- (whiteRuns+greenRuns)\n",
    "print(\"All RED scrolls collected in\", redRuns, \"runs\")\n",
    "print(\"All scrolls collected in\", numRuns, \"runs\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the state space: In this case, the state space consists of the four parameters you mentioned (trend, VWAP, RSI, and ATR). You can create a numpy array to represent the state space, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find patterns for fakeouts and breakouts\n",
    "#define breakouts and fakeouts\n",
    "\n",
    "\n",
    "prices = [10, 12, 14, 16, 18, 20, 22, 20, 18, 16]\n",
    "resistance_level = 22\n",
    "\n",
    "for i in range(len(prices)):\n",
    "    if prices[i] > resistance_level:\n",
    "        print(\"Potential breakout at index\", i, \"with price\", prices[i])\n",
    "        for j in range(i+1, len(prices)):\n",
    "            if prices[j] < resistance_level:\n",
    "                print(\"Fakeout at index\", j, \"with price\", prices[j])\n",
    "                break\n",
    "            elif j == len(prices) - 1:\n",
    "                print(\"No fakeout occurred\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VWAP (Volume Weighted Average Price)\n",
    "\n",
    "def vwap(df):\n",
    "    \"\"\"\n",
    "    Calculates the Volume Weighted Average Price (VWAP) for a given DataFrame.\n",
    "    \"\"\"\n",
    "    tp = (df[\"high\"] + df[\"low\"] + df[\"close\"]) / 3\n",
    "    vwap = (df[\"volume\"] * tp).cumsum() / df[\"volume\"].cumsum()\n",
    "    return vwap\n",
    "\n",
    "\n",
    "#ATR (Average True Range)\n",
    "\n",
    "def atr(df, period=14):\n",
    "    \"\"\"\n",
    "    Calculates the Average True Range (ATR) for a given DataFrame.\n",
    "    \"\"\"\n",
    "    high_low = df[\"high\"] - df[\"low\"]\n",
    "    high_prev_close = abs(df[\"high\"] - df[\"close\"].shift())\n",
    "    low_prev_close = abs(df[\"low\"] - df[\"close\"].shift())\n",
    "    true_range = pd.concat([high_low, high_prev_close, low_prev_close], axis=1).max(axis=1)\n",
    "    atr = true_range.rolling(period).mean()\n",
    "    return atr\n",
    "\n",
    "#Support and Resistance Levels\n",
    "\n",
    "def support(df):\n",
    "    \"\"\"\n",
    "    Calculates the support level for a given DataFrame.\n",
    "    \"\"\"\n",
    "    lows = df[\"low\"]\n",
    "    support = lows.min() + 2 * (df[\"high\"].mean() - lows.mean())\n",
    "    return support\n",
    "\n",
    "def resistance(df):\n",
    "    \"\"\"\n",
    "    Calculates the resistance level for a given DataFrame.\n",
    "    \"\"\"\n",
    "    highs = df[\"high\"]\n",
    "    resistance = highs.max() - 2 * (highs.mean() - df[\"low\"].mean())\n",
    "    return resistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RSI (Relative Strength Index)\n",
    "\n",
    "def rsi(df, period=14):\n",
    "    \"\"\"\n",
    "    Calculates the Relative Strength Index (RSI) for a given DataFrame.\n",
    "    \"\"\"\n",
    "    delta = df[\"close\"].diff()\n",
    "    up = delta.where(delta > 0, 0)\n",
    "    down = -delta.where(delta < 0, 0)\n",
    "    ema_up = up.rolling(period).mean()\n",
    "    ema_down = down.rolling(period).mean()\n",
    "    rs = ema_up / ema_down\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi\n",
    "\n",
    "def regular_divergence_rsi(df, period=14):\n",
    "    \"\"\"\n",
    "    Calculates regular RSI divergence and ratios of effectiveness for a given DataFrame.\n",
    "    \"\"\"\n",
    "    rsi = calculate_rsi(df, period)\n",
    "    price = df[\"close\"]\n",
    "    highs = df[\"high\"]\n",
    "    lows = df[\"low\"]\n",
    "    bullish_div = ((rsi < rsi.shift(1)) & (price > price.shift(1)) & (highs > highs.shift(1))) | ((rsi < rsi.shift(2)) & (price > price.shift(2)) & (highs > highs.shift(2)))\n",
    "    bearish_div = ((rsi > rsi.shift(1)) & (price < price.shift(1)) & (lows < lows.shift(1))) | ((rsi > rsi.shift(2)) & (price < price.shift(2)) & (lows < lows.shift(2)))\n",
    "    bullish_ratio = bullish_div.sum() / (rsi < 30).sum()\n",
    "    bearish_ratio = bearish_div.sum() / (rsi > 70).sum()\n",
    "    return bullish_div, bearish_div, bullish_ratio, bearish_ratio\n",
    "\n",
    "def regular_divergence_rsi_2(df, period=14):\n",
    "    \"\"\"\n",
    "    Calculates regular RSI divergence for a given DataFrame.\n",
    "    \"\"\"\n",
    "    rsi = calculate_rsi(df, period)\n",
    "    price = df[\"close\"]\n",
    "    highs = df[\"high\"]\n",
    "    lows = df[\"low\"]\n",
    "    bullish_div = ((rsi < rsi.shift(1)) & (price > price.shift(1)) & (highs > highs.shift(1))) | ((rsi < rsi.shift(2)) & (price > price.shift(2)) & (highs > highs.shift(2)))\n",
    "    bearish_div = ((rsi > rsi.shift(1)) & (price < price.shift(1)) & (lows < lows.shift(1))) | ((rsi > rsi.shift(2)) & (price < price.shift(2)) & (lows < lows.shift(2)))\n",
    "    return bullish_div, bearish_div\n",
    "\n",
    "\n",
    "def hidden_divergence_rsi(df, period=14):\n",
    "    \"\"\"\n",
    "    Calculates hidden RSI divergence for a given DataFrame.\n",
    "    \"\"\"\n",
    "    rsi = calculate_rsi(df, period)\n",
    "    price = df[\"close\"]\n",
    "    highs = df[\"high\"]\n",
    "    lows = df[\"low\"]\n",
    "    bullish_div = ((rsi > rsi.shift(1)) & (price < price.shift(1)) & (lows < lows.shift(1))) | ((rsi > rsi.shift(2)) & (price < price.shift(2)) & (lows < lows.shift(2)))\n",
    "    bearish_div = ((rsi < rsi.shift(1)) & (price > price.shift(1)) & (highs > highs.shift(1))) | ((rsi < rsi.shift(2)) & (price > price.shift(2)) & (highs > highs.shift(2)))\n",
    "    return bullish_div, bearish_div\n",
    "\n",
    "def bullish_divergence_rsi(df, period=14):\n",
    "    \"\"\"\n",
    "    Calculates bullish RSI divergence for a given DataFrame.\n",
    "    \"\"\"\n",
    "    rsi = calculate_rsi(df, period)\n",
    "    price = df[\"close\"]\n",
    "    lows = df[\"low\"]\n",
    "    bullish_div = ((rsi > rsi.shift(1)) & (price < price.shift(1)) & (lows < lows.shift(1))) | ((rsi > rsi.shift(2)) & (price < price.shift(2)) & (lows < lows.shift(2)))\n",
    "    return bullish_div\n",
    "\n",
    "def bearish_divergence_rsi(df, period=14):\n",
    "    \"\"\"\n",
    "    Calculates bearish RSI divergence for a given DataFrame.\n",
    "    \"\"\"\n",
    "    rsi = calculate_rsi(df, period)\n",
    "    price = df[\"close\"]\n",
    "    highs = df[\"high\"]\n",
    "    bearish_div = ((rsi < rsi.shift(1)) & (price > price.shift(1)) & (highs > highs.shift(1))) | ((rsi < rsi.shift(2)) & (price > price.shift(2)) & (highs > highs.shift(2)))\n",
    "    return bearish_div\n",
    "\n",
    "def calculate_slope_divergence(df, period=14):\n",
    "    \"\"\"\n",
    "    Calculates the RSI slope divergence, where RSI slope and price slope are divergent.\n",
    "    Returns a DataFrame with a column indicating bullish divergence and a column indicating bearish divergence.\n",
    "    \"\"\"\n",
    "    rsi = calculate_rsi(df, period)\n",
    "    price = df[\"close\"]\n",
    "    rsi_slope = rsi.diff()\n",
    "    price_slope = price.diff()\n",
    "    bullish_div = ((rsi_slope > 0) & (price_slope > 0) & (rsi < rsi.shift(1)) & (price > price.shift(1))) | ((rsi_slope > 0) & (price_slope < 0) & (rsi < rsi.shift(1)) & (price < price.shift(1)))\n",
    "    bearish_div = ((rsi_slope < 0) & (price_slope < 0) & (rsi > rsi.shift(1)) & (price < price.shift(1))) | ((rsi_slope < 0) & (price_slope > 0) & (rsi > rsi.shift(1)) & (price > price.shift(1)))\n",
    "    return bullish_div, bearish_div\n",
    "\n",
    "def calculate_zero_divergence(df, period=14):\n",
    "    \"\"\"\n",
    "    Calculates the zero line divergence, where RSI crosses above or below the 50 level and price continues to trend.\n",
    "    Returns a DataFrame with a column indicating bullish divergence and a column indicating bearish divergence.\n",
    "    \"\"\"\n",
    "    rsi = calculate_rsi(df, period)\n",
    "    price = df[\"close\"]\n",
    "    bullish_div = ((rsi > 50) & (rsi.shift(1) < 50) & (price > price.shift(1))) | ((rsi > 50) & (rsi.shift(1) < 50) & (price.shift(1) > price.shift(2)))\n",
    "    bearish_div = ((rsi < 50) & (rsi.shift(1) > 50) & (price < price.shift(1))) | ((rsi < 50) & (rsi.shift(1) > 50) & (price.shift(1) < price.shift(2)))\n",
    "    return bullish_div, bearish_div\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#state_space = np.array([trend, vwap, rsi, atr])\n",
    "state_space = np.array([vwap, rsi, atr])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Define the action space: The action space will depend on your specific\n",
    "    trading strategy. For example, you could define the action space as a binary\n",
    "    decision to buy or sell a stock, or you could allow the agent to decide on the size of the trade.\n",
    "    Here is an example of a binary action space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#where should go the buy and sell, the lot the edge\n",
    "action_space = gym.spaces.Discrete(4)  # 2 possible actions: buy, sell, hold and hedge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'(' was never closed (2503102793.py, line 58)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[14], line 58\u001b[1;36m\u001b[0m\n\u001b[1;33m    div_df[\"bearish_effective\"] = (div_df[\"price_high\"].pct_change() < bearish_price_mean) & (div_df[\"rsi_high\"].pct_change() < bearish_rsi\u001b[0m\n\u001b[1;37m                                                                                             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m '(' was never closed\n"
     ]
    }
   ],
   "source": [
    "def regular_divergence_rsi(df, period=14, threshold=0.05):\n",
    "    \"\"\"\n",
    "    Calculates the regular bullish and bearish RSI divergence for a given DataFrame.\n",
    "    \"\"\"\n",
    "    delta = df[\"close\"].diff()\n",
    "    up = delta.where(delta > 0, 0)\n",
    "    down = -delta.where(delta < 0, 0)\n",
    "    ema_up = up.rolling(period).mean()\n",
    "    ema_down = down.rolling(period).mean()\n",
    "    rs = ema_up / ema_down\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "\n",
    "    price = df[\"close\"]\n",
    "    price_low = price.rolling(period).min()\n",
    "    price_high = price.rolling(period).max()\n",
    "    \n",
    "    bullish_div = ((rsi.shift(1) < threshold) & (rsi > threshold) & (price_low.shift(1) < price_low)) \n",
    "    bearish_div = ((rsi.shift(1) > (100 - threshold)) & (rsi < (100 - threshold)) & (price_high.shift(1) > price_high))\n",
    "\n",
    "    # Create new dataframe with divergence data\n",
    "    div_df = pd.DataFrame({\n",
    "        \"price_low\": price_low[bullish_div].dropna(),\n",
    "        \"rsi_low\": rsi[bullish_div].dropna(),\n",
    "        \"price_high\": price_high[bearish_div].dropna(),\n",
    "        \"rsi_high\": rsi[bearish_div].dropna()\n",
    "    })\n",
    "\n",
    "    # Calculate statistics for bullish divergence\n",
    "    bullish_stats = pd.DataFrame({\n",
    "        \"price_low\": div_df[\"price_low\"],\n",
    "        \"rsi_low\": div_df[\"rsi_low\"],\n",
    "        \"price_high\": np.nan,\n",
    "        \"rsi_high\": np.nan\n",
    "    })\n",
    "    bullish_stats[\"price_change\"] = bullish_stats[\"price_low\"].pct_change()\n",
    "    bullish_stats[\"rsi_change\"] = bullish_stats[\"rsi_low\"].pct_change()\n",
    "    bullish_stats = bullish_stats.dropna()\n",
    "\n",
    "    # Calculate statistics for bearish divergence\n",
    "    bearish_stats = pd.DataFrame({\n",
    "        \"price_low\": np.nan,\n",
    "        \"rsi_low\": np.nan,\n",
    "        \"price_high\": div_df[\"price_high\"],\n",
    "        \"rsi_high\": div_df[\"rsi_high\"]\n",
    "    })\n",
    "    bearish_stats[\"price_change\"] = bearish_stats[\"price_high\"].pct_change()\n",
    "    bearish_stats[\"rsi_change\"] = bearish_stats[\"rsi_high\"].pct_change()\n",
    "    bearish_stats = bearish_stats.dropna()\n",
    "\n",
    "    # Calculate additional statistics and add effectiveness and coherence columns\n",
    "    bullish_price_mean = bullish_stats[\"price_change\"].mean()\n",
    "    bullish_rsi_mean = bullish_stats[\"rsi_change\"].mean()\n",
    "    bearish_price_mean = bearish_stats[\"price_change\"].mean()\n",
    "    bearish_rsi_mean = bearish_stats[\"rsi_change\"].mean()\n",
    "\n",
    "    div_df[\"bullish_effective\"] = (div_df[\"price_low\"].pct_change() > bullish_price_mean) & (div_df[\"rsi_low\"].pct_change() > bullish_rsi_mean)\n",
    "    div_df[\"bullish_coherent\"] = (div_df[\"price_low\"].pct_change() > 0) & (div_df[\"rsi_low\"].pct_change() > 0)\n",
    "    div_df[\"bearish_effective\"] = (div_df[\"price_high\"].pct_change() < bearish_price_mean) & (div_df[\"rsi_high\"].pct_change() < bearish_rsi\n",
    "    div_df[\"bearish_coherent\"] = (div_df[\"price_high\"].pct_change() < 0) & (div_df[\"rsi_high\"].pct_change() < 0)\n",
    "\n",
    "    return div_df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the environment: You can use the gym library to create a custom environment that encapsulates the state space, action space, and reward function. Here is an example of a custom environment class:\n",
    "I NEED UNDERSTAND BETTER WHAT IS THIS DOING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'if' statement on line 18 (1548257286.py, line 21)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[16], line 21\u001b[1;36m\u001b[0m\n\u001b[1;33m    else:\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after 'if' statement on line 18\n"
     ]
    }
   ],
   "source": [
    "class TradingEnvironment(gym.Env):\n",
    "    def __init__(self, initial_balance, price_data):\n",
    "        self.initial_balance = initial_balance\n",
    "        self.price_data = price_data\n",
    "        self.current_step = 0\n",
    "        self.balance = self.initial_balance\n",
    "        self.state_space = gym.spaces.Box(low=0, high=1, shape=(4,))\n",
    "        self.action_space = gym.spaces.Discrete(2)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        self.balance = self.initial_balance\n",
    "        state = self._get_state()\n",
    "        return state\n",
    "    \n",
    "    def step(self, action):\n",
    "        # Execute the trade based on the action\n",
    "        if action == 0:\n",
    "            # Buy\n",
    "            # ...\n",
    "        else:\n",
    "            # Sell\n",
    "            # ...\n",
    "        \n",
    "        # Calculate profit/loss and update balance\n",
    "        profit = ...\n",
    "        self.balance += profit\n",
    "        \n",
    "        # Get the next state\n",
    "        self.current_step += 1\n",
    "        state = self._get_state()\n",
    "        \n",
    "        # Calculate reward based on profit\n",
    "        reward = reward_function(profit)\n",
    "        \n",
    "        # Check if done (end of time period or account depleted)\n",
    "        done = ...\n",
    "        \n",
    "        # Return observation, reward, done, and info\n",
    "        return state, reward, done, {}\n",
    "        \n",
    "    def _get_state(self):\n",
    "        # Calculate trend, VWAP, RSI, and ATR\n",
    "        trend = ...\n",
    "        vwap = ...\n",
    "        rsi = ...\n",
    "        atr = ...\n",
    "        \n",
    "        # Normalize state space to range [0, 1]\n",
    "        state = np.array([trend, vwap, rsi, atr])\n",
    "        state = (state - self.state_space.low) / (self.state_space.high - self.state_space.low)\n",
    "        \n",
    "        return state\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input parameters like trendline, price actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'stock_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Load stock data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39mstock_data.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      4\u001b[0m \u001b[39m# Calculate trendlines\u001b[39;00m\n\u001b[0;32m      5\u001b[0m y \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mClose\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1736\u001b[0m     f,\n\u001b[0;32m   1737\u001b[0m     mode,\n\u001b[0;32m   1738\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1739\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1740\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1741\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1742\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1743\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1744\u001b[0m )\n\u001b[0;32m   1745\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    859\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    860\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    861\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'stock_data.csv'"
     ]
    }
   ],
   "source": [
    "# Load stock data\n",
    "df = pd.read_csv('stock_data.csv')\n",
    "\n",
    "# Calculate trendlines\n",
    "y = df['Close']\n",
    "trendline1 = (y.iloc[0] + y.iloc[-1]) / 2 # Start with a horizontal line\n",
    "trendline2 = (y.iloc[0] + y.iloc[-1]) / 2 # Start with a horizontal line\n",
    "for i in range(1, len(y)):\n",
    "    if y[i] > trendline1:\n",
    "        trendline1 += (y[i] - trendline1) * 0.05 # Adjust trendline slope based on price movement\n",
    "    if y[i] < trendline2:\n",
    "        trendline2 += (y[i] - trendline2) * 0.05 # Adjust trendline slope based on price movement\n",
    "\n",
    "# Print trendlines\n",
    "print(\"Trendline 1: \", trendline1)\n",
    "print(\"Trendline 2: \", trendline2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate price action\n",
    "y = df['Close']\n",
    "highs = [y[0]]\n",
    "lows = [y[0]]\n",
    "for i in range(1, len(y)):\n",
    "    if y[i] > highs[-1]:\n",
    "        highs.append(y[i])\n",
    "    else:\n",
    "        highs.append(highs[-1])\n",
    "    if y[i] < lows[-1]:\n",
    "        lows.append(y[i])\n",
    "    else:\n",
    "        lows.append(lows[-1])\n",
    "\n",
    "# Print price action\n",
    "print(\"Highs: \", highs)\n",
    "print(\"Lows: \", lows)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the reward function: As mentioned earlier, the reward function will depend on your investment strategy. For example, you could define the reward as the change in account balance over a period of time. Here is an example of a simple reward function that gives a positive reward for each profitable trade:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reenforcement learnig tryout\n",
    "\n",
    "#trying do define the varoius cenarios of rewards from optimal gaining to losses\n",
    "#Gaining 10% gains in a day comulative and individual 20 units for each goal\n",
    "#.it takes 10 trades makes 20 units for making comulative and individual units for each traid\n",
    "#  if the trade was profitable 1 unit\n",
    "# with no significant drawdown 1 unit\n",
    "# in less time 1 unit\n",
    "# with  loss -1 unit\n",
    "# if drawdowns significantly -1 or -2 units\n",
    "# if losses above 5% -10, comulative or individual -20\n",
    "\n",
    "\n",
    "def reward_function(profit, tradeable_money, maxDrawdown, drawdownCount):\n",
    "    #scale from 0 to 10 the poinst fom the way thtat profits by time amount and benchmark\n",
    "    rewardValue = 0\n",
    "    if profit < 0:\n",
    "        rewardValue-= 1\n",
    "    if profit > 0:\n",
    "        rewardValue+= 1\n",
    "    if profit > tradeable_money*.1:\n",
    "        rewardValue+= 10\n",
    "    if drawdownCount > 3:\n",
    "        rewardValue+= 10\n",
    "    if maxDrawdown > 200:#should be calculated the value of the investment and the risk reward ratio and stuff\n",
    "        rewardValue+= 10\n",
    "    if rewardValue > 10 and rewardValue < 20:\n",
    "        print(\"unlucked the first layer of the rewards\")\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "47e86e659cc4c7e7c8281f4dfa198d26eba569ed7d4f5779d5419dff2bd0d92c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
